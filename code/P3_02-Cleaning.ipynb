{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Trebuchet MS; font-size:2em;\">Project 3 | NB2: Cleaning and Preprocessing</span>\n",
    "\n",
    "Riley Robertson | Reddit Classification Project | Market Research: Sports Fans in the U.S. and England"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports and setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I began my process by importing basic libraries and as I cleaned, I returned to add modules as necessary. I also set preferences, assigned variables, imported my data, and set up my main dataframe so I could begin cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:41.511058Z",
     "start_time": "2021-05-03T10:07:39.738461Z"
    }
   },
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# custom\n",
    "import utilities.densmore as dns\n",
    "\n",
    "# date and time \n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "# for CVEC test\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:41.515929Z",
     "start_time": "2021-05-03T10:07:41.512654Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:42.932394Z",
     "start_time": "2021-05-03T10:07:41.518307Z"
    }
   },
   "outputs": [],
   "source": [
    "df_nfl = pd.read_csv('../data/1_raw/raw_nfl_v4.csv', low_memory=False)\n",
    "df_epl = pd.read_csv('../data/1_raw/raw_epl_v4.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:42.938893Z",
     "start_time": "2021-05-03T10:07:42.934276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99661, 13), (99589, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfl.shape, df_epl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:42.942913Z",
     "start_time": "2021-05-03T10:07:42.940818Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_nfl_full = pd.read_csv('../git_ignore/output/raw_nfl_v4_full.csv', low_memory=False)\n",
    "# df_epl_full = pd.read_csv('../git_ignore/output/raw_epl_v4_full.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:42.946525Z",
     "start_time": "2021-05-03T10:07:42.944659Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_nfl_full.shape, df_epl_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:42.991678Z",
     "start_time": "2021-05-03T10:07:42.949256Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_epl, df_nfl], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:42.996762Z",
     "start_time": "2021-05-03T10:07:42.994953Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_full = pd.concat([df_epl_full, df_nfl_full], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.105404Z",
     "start_time": "2021-05-03T10:07:43.000479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199250 entries, 0 to 199249\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   index            199250 non-null  int64 \n",
      " 1   subreddit        199250 non-null  object\n",
      " 2   created_utc      199250 non-null  int64 \n",
      " 3   author           199250 non-null  object\n",
      " 4   num_comments     199250 non-null  int64 \n",
      " 5   score            199250 non-null  int64 \n",
      " 6   is_self          199250 non-null  bool  \n",
      " 7   link_flair_text  29684 non-null   object\n",
      " 8   title            199250 non-null  object\n",
      " 9   selftext         168312 non-null  object\n",
      " 10  full_link        199250 non-null  object\n",
      " 11  date             199250 non-null  object\n",
      " 12  time             199250 non-null  object\n",
      "dtypes: bool(1), int64(4), object(8)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# df.shape\n",
    "# df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Text Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Chardetect terminal command**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.109161Z",
     "start_time": "2021-05-03T10:07:43.107087Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! chardetect ../data/raw/raw_nfl_v4.csv  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using `with open()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.113822Z",
     "start_time": "2021-05-03T10:07:43.111448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('../data/raw/raw_nfl_v4.csv') as f:\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming PremierLeague Subreddit to 'epl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.133327Z",
     "start_time": "2021-05-03T10:07:43.115944Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl              99661\n",
       "PremierLeague    99589\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.162149Z",
     "start_time": "2021-05-03T10:07:43.135036Z"
    }
   },
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map(lambda x: 'epl' if x == 'PremierLeague' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.184229Z",
     "start_time": "2021-05-03T10:07:43.163859Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    99661\n",
       "epl    99589\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Sorting and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I cleaned, I realized that there were some columns that I didn't ultimately need, so I filtered out some of the columns that I initially included in my scraped data and resorted the remaining columns for ease of viewing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.210390Z",
     "start_time": "2021-05-03T10:07:43.186621Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['subreddit', 'created_utc', 'date', 'time', 'link_flair_text', 'author', 'score', 'num_comments', 'index',  'title', 'selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.218930Z",
     "start_time": "2021-05-03T10:07:43.213727Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.241413Z",
     "start_time": "2021-05-03T10:07:43.222201Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    99661\n",
       "epl    99589\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the value counts above, I'm starting out with about 100,000 posts for each subreddit. I originally started with fewer, but after I began cleaning, I was quickly running of posts that that had the conditions I wanted. I returned to my Data Collection notebook and increased the number of posts to request from the API so that I'd begin my cleaning with a much greater volume of posts than I would eventually need. That way, I could be more decisive in dropping rows rather than trying to salvage content from posts that had incomplete or low quality information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Basic Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nulls only exist in two columns: `link_flair_text` and `selftext`. \n",
    "\n",
    "I knew I had enough data that I could drop all of the posts with empty `selftext` fields, but I didn't want to lose the posts without tags (there are many). So I put 'none' into the `link_flair_text` fields and removed all rows with nulls after that, which left about 80,000 posts per subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.309774Z",
     "start_time": "2021-05-03T10:07:43.243935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199250 entries, 0 to 199249\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   subreddit        199250 non-null  object\n",
      " 1   created_utc      199250 non-null  int64 \n",
      " 2   date             199250 non-null  object\n",
      " 3   time             199250 non-null  object\n",
      " 4   link_flair_text  29684 non-null   object\n",
      " 5   author           199250 non-null  object\n",
      " 6   score            199250 non-null  int64 \n",
      " 7   num_comments     199250 non-null  int64 \n",
      " 8   index            199250 non-null  int64 \n",
      " 9   title            199250 non-null  object\n",
      " 10  selftext         168312 non-null  object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.326267Z",
     "start_time": "2021-05-03T10:07:43.311940Z"
    }
   },
   "outputs": [],
   "source": [
    "df['link_flair_text'].fillna('none', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.330271Z",
     "start_time": "2021-05-03T10:07:43.327936Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.460979Z",
     "start_time": "2021-05-03T10:07:43.333680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 168312 entries, 0 to 199248\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   subreddit        168312 non-null  object\n",
      " 1   created_utc      168312 non-null  int64 \n",
      " 2   date             168312 non-null  object\n",
      " 3   time             168312 non-null  object\n",
      " 4   link_flair_text  168312 non-null  object\n",
      " 5   author           168312 non-null  object\n",
      " 6   score            168312 non-null  int64 \n",
      " 7   num_comments     168312 non-null  int64 \n",
      " 8   index            168312 non-null  int64 \n",
      " 9   title            168312 non-null  object\n",
      " 10  selftext         168312 non-null  object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.477408Z",
     "start_time": "2021-05-03T10:07:43.462503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epl    86351\n",
       "nfl    81961\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicates brings down PremierLeague posts to a good range, but the number of NFL posts is still much greater than necessary. As I move forward, I'll work on bringing down the number of NFL posts to at least roughly match that of the PremierLeague posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.527022Z",
     "start_time": "2021-05-03T10:07:43.483216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59730, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['title'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.540001Z",
     "start_time": "2021-05-03T10:07:43.531496Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    53173\n",
       "epl     6557\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.774163Z",
     "start_time": "2021-05-03T10:07:43.541849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56178, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['selftext'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.786540Z",
     "start_time": "2021-05-03T10:07:43.775875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    49832\n",
       "epl     6346\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts with deleted body text (selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.838817Z",
     "start_time": "2021-05-03T10:07:43.788183Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    49831\n",
       "epl     6324\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(axis=0, \n",
    "        labels=df[df['selftext'].str.startswith('[deleted]')].index, # Submissions with deleted selftext\n",
    "        inplace=True)\n",
    "\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts with Markdown tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.896260Z",
     "start_time": "2021-05-03T10:07:43.840286Z"
    }
   },
   "outputs": [],
   "source": [
    "markdowns = df[df['selftext'].str.contains('\\|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.902384Z",
     "start_time": "2021-05-03T10:07:43.897770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    3906\n",
       "epl     201\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdowns['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.924367Z",
     "start_time": "2021-05-03T10:07:43.904265Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(axis=0, labels=markdowns.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.928793Z",
     "start_time": "2021-05-03T10:07:43.926630Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['selftext'] = df['selftext'].replace('http\\S+', '', regex=True).replace('www\\S+', '', regex=True)\n",
    "# df['title'] = df['title'].replace('http\\S+', '', regex=True).replace('www\\S+', '', regex=True)\n",
    "\n",
    "# https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/40823105#40823105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:43.938654Z",
     "start_time": "2021-05-03T10:07:43.930837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I get help from  and I learn a lot reading on '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_url(text):\n",
    "    import re\n",
    "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "\n",
    "# Gwens string didn't work for me:\n",
    "# r'^https?:\\/\\/.*[\\r\\n]*'\n",
    "\n",
    "sentence = 'I get help from https://stackoverflow.com and I learn a lot reading on https://towardsdatascience.com'\n",
    "\n",
    "remove_url(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.123763Z",
     "start_time": "2021-05-03T10:07:43.941911Z"
    }
   },
   "outputs": [],
   "source": [
    "df['selftext'] = df['selftext'].map(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.129059Z",
     "start_time": "2021-05-03T10:07:46.126916Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df['selftext'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Post Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I got the duplicates removal code working above, I manually went through a list of the most commonly repeating post `'selftext'` and cleared them out with a list and a for-loop. I'm going to remove a bulk of that code since it's no longer necessary, but some of it is still relevant, even after removing duplicates with the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.133156Z",
     "start_time": "2021-05-03T10:07:46.131141Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df['selftext'].value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.136779Z",
     "start_time": "2021-05-03T10:07:46.134983Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the value counts for the 'selftext' field, I realized that there were a lot of posts that had the exact same body text. So I used the following code to look at the top 20 most common titles and there were quite a few that were re-used many times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.143447Z",
     "start_time": "2021-05-03T10:07:46.140048Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# df['title'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readable results from above code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Post Title                                         | Count | ┃ | Post Title                          | Count | ┃ | Post Title                                   | Count |\n",
    "|:---------------------------------------------------|:------|:-:|:------------------------------------|:------|:-:|:---------------------------------------------|:------|\n",
    "| Shitpost Saturday                                  | 174   | ┃ | Talko Tuesday                       | 124   | ┃ | r/PremierLeague Midweek Musings              | 13    |\n",
    "| Water Cooler Wednesday                             | 159   | ┃ | r/PremierLeague Daily Discussion    | 71    | ┃ | Weekly /r/PremierLeague Subreddit Suggestion | 11    |\n",
    "| Free Talk Friday                                   | 158   | ┃ | This Week's Top /r/NFL [Highlight]s | 22    | ┃ | Test                                         | 11    |\n",
    "| Sunday Brunch                                      | 157   | ┃ | Weekend Wrap Up                     | 21    | ┃ | Daily Open Discussion Thread                 | 11    |\n",
    "| Thursday Talk Thread... Yes That's The Thread Name | 141   | ┃ | Question                            | 15    | ┃ | Weekly Transfer Discussion Thread            | 8     |\n",
    "| Weekend Wrapup                                     | 130   | ┃ | NFL Power Rankings (Combined)       | 15    | ┃ | test                                         | 7     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They fell into several categories:\n",
    "1. Open threads meant for discussion of topics of any kind, even if unrelated to the topic of the subreddit.\n",
    "2. Discussion threads in which the topics might be related, but all of the content is in the comments rather than the body of the post\n",
    "3. Posts with code and/or little-to-no useful content\n",
    "4. Commonly used titles by different users to introduce a topic-relevant post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.149027Z",
     "start_time": "2021-05-03T10:07:46.145321Z"
    }
   },
   "outputs": [],
   "source": [
    "repeat_titles = [\"Shitpost Saturday\", \"Water Cooler Wednesday\", \"Free Talk Friday\", \"Sunday Brunch\", \n",
    "                 \"Thursday Talk Thread... Yes That's The Thread Name\", \"Weekend Wrapup\", \"Talko Tuesday\",\n",
    "                 \"r/PremierLeague Daily Discussion\", \"This Week's Top /r/NFL [Highlight]s\", \n",
    "                 \"Weekend Wrap Up\", \"NFL Power Rankings (Combined)\", \"r/PremierLeague Midweek Musings\", \n",
    "                 \"Whose Line is it Anyways Wednesday--Offseason Edition\", \n",
    "                 \"Weekly /r/PremierLeague Subreddit Suggestion\", \"Test\", \"Daily Open Discussion Thread\",\n",
    "                 \"Weekly Transfer Discussion Thread\", \"test\", \"Your Weekly /r/nfl Recap\", \n",
    "                 \"NFL Power Rankings (Combined) Week 0\",\n",
    "                 \"Should Ole stay at Manchester United or not? If he got sacked by the board, who will be the best replacement. Comment your thoughts below\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.470624Z",
     "start_time": "2021-05-03T10:07:46.151565Z"
    }
   },
   "outputs": [],
   "source": [
    "for title in repeat_titles:\n",
    "    title_df = df[df['title'] == title]  \n",
    "    df.drop(axis=0, labels=title_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.474430Z",
     "start_time": "2021-05-03T10:07:46.472224Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['title'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.485831Z",
     "start_time": "2021-05-03T10:07:46.476338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    45921\n",
       "epl     6117\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PremierLeague Poll Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found 91 posts from the PremierLeague subreddit that contained a lot of unnecessary information and formatting was such that vectorizing would be significantly more complicated. I decided to simply remove them for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.495484Z",
     "start_time": "2021-05-03T10:07:46.488004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('[View Poll](https://www.reddit.com/poll/g437k5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.530404Z",
     "start_time": "2021-05-03T10:07:46.497262Z"
    }
   },
   "outputs": [],
   "source": [
    "poll_posts = df[df['selftext'].str.startswith('  [View Poll]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.535514Z",
     "start_time": "2021-05-03T10:07:46.532055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poll_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.548201Z",
     "start_time": "2021-05-03T10:07:46.537057Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(axis=0, labels=poll_posts.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.557930Z",
     "start_time": "2021-05-03T10:07:46.549798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    45921\n",
       "epl     6117\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PremierLeague Match Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found 91 posts from the PremierLeague subreddit that contained a lot of unnecessary information and formatting was such that vectorizing would be significantly more complicated. I decided to simply remove them for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.561687Z",
     "start_time": "2021-05-03T10:07:46.559622Z"
    }
   },
   "outputs": [],
   "source": [
    "match_thread_titles = ('[Match Thread]', \n",
    "                       '[Match thread]', \n",
    "                       '[match Thread]', \n",
    "                       '[match thread]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.588710Z",
     "start_time": "2021-05-03T10:07:46.563445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    52029\n",
       "True         9\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.startswith(match_thread_titles).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.612279Z",
     "start_time": "2021-05-03T10:07:46.590241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    52029\n",
       "True         9\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.startswith(match_thread_titles).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.636961Z",
     "start_time": "2021-05-03T10:07:46.615045Z"
    }
   },
   "outputs": [],
   "source": [
    "match_threads = df[df['title'].str.startswith(match_thread_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.643161Z",
     "start_time": "2021-05-03T10:07:46.638647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_threads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.656265Z",
     "start_time": "2021-05-03T10:07:46.645132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    45921\n",
       "epl     6117\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing NFL posts with Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game Thread, Serious, Look Here!, and others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.668899Z",
     "start_time": "2021-05-03T10:07:46.658090Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Look Here!                        1805\n",
       "Game Thread                       1061\n",
       "Serious                            748\n",
       "Free Talk                          492\n",
       "Free talk                          437\n",
       "Removed: Rule 2 - Invalid Post     116\n",
       "Post Game Thread                    72\n",
       "Trash Talk                          60\n",
       "Look Here                           51\n",
       "game                                42\n",
       "Name: link_flair_text, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfl['link_flair_text'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.686310Z",
     "start_time": "2021-05-03T10:07:46.671123Z"
    }
   },
   "outputs": [],
   "source": [
    "nfl_with_tags = df[(df['link_flair_text'] != 'none') & (df['subreddit'] == 'nfl')]\n",
    "df.drop(axis=0, labels=nfl_with_tags.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.695757Z",
     "start_time": "2021-05-03T10:07:46.687679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                       47228\n",
       "Discussion                  1583\n",
       "Question                     919\n",
       "Poll                         564\n",
       ":xpl: Premier League         246\n",
       "News                          79\n",
       ":mun: Manchester United       72\n",
       ":liv: Liverpool               62\n",
       ":ars: Arsenal                 57\n",
       ":che: Chelsea                 53\n",
       "Name: link_flair_text, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['link_flair_text'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.718048Z",
     "start_time": "2021-05-03T10:07:46.697332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    45124\n",
       "epl     5553\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(axis=0, labels=df[(df['link_flair_text'] == 'Poll')].index, inplace=True)\n",
    "\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFL Posts Filtered by String Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the number of posts I had from the r/nfl, I decided to filter based on length.\n",
    "\n",
    "First, I created a DataFrame that contained only nfl posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.731728Z",
     "start_time": "2021-05-03T10:07:46.719754Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45124, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['subreddit'] == 'nfl']\n",
    "\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a second DataFrame that contained only the rows I want to keep (rows with post lengths between 500 and 1200 characters was where I landed after several tests until I got the count of NFL posts down to a similar number as that of the EPL posts.\n",
    "\n",
    "Taking this slightly roundabout way allowed me to see the number of posts I'd have remaining once I removed the excess from the main DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.791584Z",
     "start_time": "2021-05-03T10:07:46.733312Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6981, 11)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lengthlimits = df[(df['selftext'].str.len()>500) & \\\n",
    "                     (df['selftext'].str.len()<1200) & \\\n",
    "                     (df['subreddit'] == 'nfl')]\n",
    "df_lengthlimits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the index of that second DataFrame, I removed all the posts I want to keep from the DataFrame I created above: 'df_filtered', thus giving me a DataFrame containing all of the posts I want to exclude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.806785Z",
     "start_time": "2021-05-03T10:07:46.793327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_filtered.drop(axis=0, labels=df_lengthlimits.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.814618Z",
     "start_time": "2021-05-03T10:07:46.808897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38143, 11)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that filtered DataFrame, I was able to use its index to drop all of the unwanted posts from the primary DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.830941Z",
     "start_time": "2021-05-03T10:07:46.817231Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(axis=0, labels=df_filtered.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.840089Z",
     "start_time": "2021-05-03T10:07:46.832736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    6981\n",
       "epl    5553\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on, I realized that there some extremely long posts (upwards of 25,000-30,000 characters) on the epl page that really skewed my distributions in the EDA section. I came back to remove those outliers and then move forward again from here.\n",
    "\n",
    "The content is valuable, though, so I didn't want to trim too much. rather than trimming as far as a max of 1200 characters like I did for the NFL posts, I cut it off at 3,000. The distribution will still be off, but not nearly to the severe degree it was before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.853608Z",
     "start_time": "2021-05-03T10:07:46.841876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 11)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['subreddit'] == 'epl') & (df['selftext'].str.len()>3000)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.874272Z",
     "start_time": "2021-05-03T10:07:46.863543Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['selftext'].str.len()<3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.880623Z",
     "start_time": "2021-05-03T10:07:46.877467Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12416, 11)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.889652Z",
     "start_time": "2021-05-03T10:07:46.882368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    6981\n",
       "epl    5435\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing so many rows, the DataFrame's index had gaps in its sequencing, so I decided to reset it to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.893608Z",
     "start_time": "2021-05-03T10:07:46.891444Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.907524Z",
     "start_time": "2021-05-03T10:07:46.895593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619271770</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>06:42:50</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>CC-33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>My thoughts and prayers are with Jurgen Klopp ...</td>\n",
       "      <td>Imagine being Jurgen Klopp right now, arguably...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619278607</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>08:36:47</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Cheerful_Jerry9603</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>Premier League Players who should finish off t...</td>\n",
       "      <td>Chinese Super League is known to be the last p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619283368</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>09:56:08</td>\n",
       "      <td>Question</td>\n",
       "      <td>alphaftw1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>Hypothetical situation, what happens if both c...</td>\n",
       "      <td>So let’s say this season, arsenal win the euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619283692</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>10:01:32</td>\n",
       "      <td>Question</td>\n",
       "      <td>imjonathvn</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>Norwich, Watford, and Bournemouth might all ge...</td>\n",
       "      <td>Norwich and Watford have already been promoted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  created_utc        date      time link_flair_text  \\\n",
       "7        epl   1619271770  2021-04-24  06:42:50      Discussion   \n",
       "9        epl   1619278607  2021-04-24  08:36:47      Discussion   \n",
       "14       epl   1619283368  2021-04-24  09:56:08        Question   \n",
       "15       epl   1619283692  2021-04-24  10:01:32        Question   \n",
       "\n",
       "                author  score  num_comments  index  \\\n",
       "7                CC-33      1             3      7   \n",
       "9   Cheerful_Jerry9603      1             2      9   \n",
       "14           alphaftw1      1             8     14   \n",
       "15          imjonathvn      1            24     15   \n",
       "\n",
       "                                                title  \\\n",
       "7   My thoughts and prayers are with Jurgen Klopp ...   \n",
       "9   Premier League Players who should finish off t...   \n",
       "14  Hypothetical situation, what happens if both c...   \n",
       "15  Norwich, Watford, and Bournemouth might all ge...   \n",
       "\n",
       "                                             selftext  \n",
       "7   Imagine being Jurgen Klopp right now, arguably...  \n",
       "9   Chinese Super League is known to be the last p...  \n",
       "14  So let’s say this season, arsenal win the euro...  \n",
       "15  Norwich and Watford have already been promoted...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[5:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'index' column can serve as a record of each posts original index number in case it's ever needed going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.911425Z",
     "start_time": "2021-05-03T10:07:46.909282Z"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.923324Z",
     "start_time": "2021-05-03T10:07:46.913185Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619271770</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>06:42:50</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>CC-33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>My thoughts and prayers are with Jurgen Klopp ...</td>\n",
       "      <td>Imagine being Jurgen Klopp right now, arguably...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619278607</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>08:36:47</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Cheerful_Jerry9603</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>Premier League Players who should finish off t...</td>\n",
       "      <td>Chinese Super League is known to be the last p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619283368</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>09:56:08</td>\n",
       "      <td>Question</td>\n",
       "      <td>alphaftw1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>Hypothetical situation, what happens if both c...</td>\n",
       "      <td>So let’s say this season, arsenal win the euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>epl</td>\n",
       "      <td>1619283692</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>10:01:32</td>\n",
       "      <td>Question</td>\n",
       "      <td>imjonathvn</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>Norwich, Watford, and Bournemouth might all ge...</td>\n",
       "      <td>Norwich and Watford have already been promoted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  created_utc        date      time link_flair_text  \\\n",
       "5       epl   1619271770  2021-04-24  06:42:50      Discussion   \n",
       "6       epl   1619278607  2021-04-24  08:36:47      Discussion   \n",
       "7       epl   1619283368  2021-04-24  09:56:08        Question   \n",
       "8       epl   1619283692  2021-04-24  10:01:32        Question   \n",
       "\n",
       "               author  score  num_comments  index  \\\n",
       "5               CC-33      1             3      7   \n",
       "6  Cheerful_Jerry9603      1             2      9   \n",
       "7           alphaftw1      1             8     14   \n",
       "8          imjonathvn      1            24     15   \n",
       "\n",
       "                                               title  \\\n",
       "5  My thoughts and prayers are with Jurgen Klopp ...   \n",
       "6  Premier League Players who should finish off t...   \n",
       "7  Hypothetical situation, what happens if both c...   \n",
       "8  Norwich, Watford, and Bournemouth might all ge...   \n",
       "\n",
       "                                            selftext  \n",
       "5  Imagine being Jurgen Klopp right now, arguably...  \n",
       "6  Chinese Super League is known to be the last p...  \n",
       "7  So let’s say this season, arsenal win the euro...  \n",
       "8  Norwich and Watford have already been promoted...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[5:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Column Clean-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.926975Z",
     "start_time": "2021-05-03T10:07:46.924986Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming 'selftext' to 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.931554Z",
     "start_time": "2021-05-03T10:07:46.928574Z"
    }
   },
   "outputs": [],
   "source": [
    "df['post'] = df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.949371Z",
     "start_time": "2021-05-03T10:07:46.933444Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns='selftext', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 'title' and 'post' into an 'alltext' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.967983Z",
     "start_time": "2021-05-03T10:07:46.951322Z"
    }
   },
   "outputs": [],
   "source": [
    "df['alltext'] = df['title'] + ' ' + df['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.975014Z",
     "start_time": "2021-05-03T10:07:46.969787Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:46.992141Z",
     "start_time": "2021-05-03T10:07:46.977187Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>alltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>If anyone thought Chris Wilder wasn’t doing a good job.</td>\n",
       "      <td>If anyone thought that Chris Wilder wasn’t doing a good job then you have to look no further than today’s game. Leicester played brilliantly of course, but we were abysmal. Since we were promoted to the premier league a couple of seasons ago we haven’t lost a game by more than a 3 goal margin. The first game Wilder isn’t in charge and we let 5 in. This was one of the best defences in the league last season. And to add insult to injury, we had 1 shot in the whole damn game. Of course we haven’t been prolific all season and haven’t scored enough goals. But one damn shot the whole game is pathetic. To me this just shows how good a manager Wilder is, he took league 1 players and made them perform way above themselves. Without him we will absolutely capitulate.</td>\n",
       "      <td>If anyone thought Chris Wilder wasn’t doing a good job. If anyone thought that Chris Wilder wasn’t doing a good job then you have to look no further than today’s game. Leicester played brilliantly of course, but we were abysmal. Since we were promoted to the premier league a couple of seasons ago we haven’t lost a game by more than a 3 goal margin. The first game Wilder isn’t in charge and we let 5 in. This was one of the best defences in the league last season. And to add insult to injury, we had 1 shot in the whole damn game. Of course we haven’t been prolific all season and haven’t scored enough goals. But one damn shot the whole game is pathetic. To me this just shows how good a manager Wilder is, he took league 1 players and made them perform way above themselves. Without him we will absolutely capitulate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "343  If anyone thought Chris Wilder wasn’t doing a good job.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               post  \\\n",
       "343  If anyone thought that Chris Wilder wasn’t doing a good job then you have to look no further than today’s game. Leicester played brilliantly of course, but we were abysmal. Since we were promoted to the premier league a couple of seasons ago we haven’t lost a game by more than a 3 goal margin. The first game Wilder isn’t in charge and we let 5 in. This was one of the best defences in the league last season. And to add insult to injury, we had 1 shot in the whole damn game. Of course we haven’t been prolific all season and haven’t scored enough goals. But one damn shot the whole game is pathetic. To me this just shows how good a manager Wilder is, he took league 1 players and made them perform way above themselves. Without him we will absolutely capitulate.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    alltext  \n",
       "343  If anyone thought Chris Wilder wasn’t doing a good job. If anyone thought that Chris Wilder wasn’t doing a good job then you have to look no further than today’s game. Leicester played brilliantly of course, but we were abysmal. Since we were promoted to the premier league a couple of seasons ago we haven’t lost a game by more than a 3 goal margin. The first game Wilder isn’t in charge and we let 5 in. This was one of the best defences in the league last season. And to add insult to injury, we had 1 shot in the whole damn game. Of course we haven’t been prolific all season and haven’t scored enough goals. But one damn shot the whole game is pathetic. To me this just shows how good a manager Wilder is, he took league 1 players and made them perform way above themselves. Without him we will absolutely capitulate.  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks\n",
    "pd.DataFrame(df.iloc[343]).T[['title', 'post', 'alltext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.007760Z",
     "start_time": "2021-05-03T10:07:46.994959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(821, 822)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.DataFrame(df.iloc[343]).T['title'][343]) + len(pd.DataFrame(df.iloc[343]).T['post'][343]), \\\n",
    "len(pd.DataFrame(df.iloc[343]).T['alltext'][343])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming 'num_comments' to 'comments'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortening column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.020761Z",
     "start_time": "2021-05-03T10:07:47.009762Z"
    }
   },
   "outputs": [],
   "source": [
    "df['comments'] = df['num_comments']\n",
    "\n",
    "df.drop(columns='num_comments', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming 'link_flair_text' to 'tag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.032993Z",
     "start_time": "2021-05-03T10:07:47.022613Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tag'] = df['link_flair_text']\n",
    "\n",
    "df.drop(columns='link_flair_text', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 'target' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I created a column that represents each row's subreddits as a 1 or 0, which will allow our models to easily recognize and interact with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.042071Z",
     "start_time": "2021-05-03T10:07:47.035098Z"
    }
   },
   "outputs": [],
   "source": [
    "df['target'] = df['subreddit'].map(lambda x: 1 if x == 'nfl' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ordering columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T02:34:07.230275Z",
     "start_time": "2021-05-03T02:34:07.225573Z"
    }
   },
   "source": [
    "Old Order:\n",
    "\n",
    "'subreddit',  \n",
    "'created_utc', 'date', 'time',  \n",
    "'link_flair_text', 'author', 'score', 'num_comments',  \n",
    "'index',  'title', 'selftext'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.050179Z",
     "start_time": "2021-05-03T10:07:47.043743Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[[\n",
    "        'subreddit', \n",
    "         'target', \n",
    "         'author', \n",
    "         'score', \n",
    "         'comments', \n",
    "         'tag', \n",
    "         'index',\n",
    "         'created_utc', \n",
    "         'date', \n",
    "         'time',\n",
    "         'title', \n",
    "         'post', \n",
    "         'alltext'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.068192Z",
     "start_time": "2021-05-03T10:07:47.052454Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12416 entries, 0 to 12415\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subreddit    12416 non-null  object\n",
      " 1   target       12416 non-null  int64 \n",
      " 2   author       12416 non-null  object\n",
      " 3   score        12416 non-null  int64 \n",
      " 4   comments     12416 non-null  int64 \n",
      " 5   tag          12416 non-null  object\n",
      " 6   index        12416 non-null  int64 \n",
      " 7   created_utc  12416 non-null  int64 \n",
      " 8   date         12416 non-null  object\n",
      " 9   time         12416 non-null  object\n",
      " 10  title        12416 non-null  object\n",
      " 11  post         12416 non-null  object\n",
      " 12  alltext      12416 non-null  object\n",
      "dtypes: int64(5), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.076057Z",
     "start_time": "2021-05-03T10:07:47.070312Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    6981\n",
       "epl    5435\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.083503Z",
     "start_time": "2021-05-03T10:07:47.077750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    0.562258\n",
       "epl    0.437742\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.097806Z",
     "start_time": "2021-05-03T10:07:47.085240Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>target</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>comments</th>\n",
       "      <th>tag</th>\n",
       "      <th>index</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>alltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>epl</td>\n",
       "      <td>0</td>\n",
       "      <td>Year-Representative</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Question</td>\n",
       "      <td>10267</td>\n",
       "      <td>1601401634</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>10:47:14</td>\n",
       "      <td>Someone please explain me the Handball rule</td>\n",
       "      <td>What constitutes a handball? What is considere...</td>\n",
       "      <td>Someone please explain me the Handball rule Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>epl</td>\n",
       "      <td>0</td>\n",
       "      <td>maseone2nine</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>10270</td>\n",
       "      <td>1601405960</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>11:59:20</td>\n",
       "      <td>Spurs crowd noise is ATROCIOUS</td>\n",
       "      <td>Every Spurs home game they absolutely BLAST th...</td>\n",
       "      <td>Spurs crowd noise is ATROCIOUS Every Spurs hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>epl</td>\n",
       "      <td>0</td>\n",
       "      <td>roots235</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>10272</td>\n",
       "      <td>1601413758</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>14:09:18</td>\n",
       "      <td>Better epl duo? Ronaldo and rooney vs mo and s...</td>\n",
       "      <td>For me, rooney and ronaldo had better link up ...</td>\n",
       "      <td>Better epl duo? Ronaldo and rooney vs mo and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>epl</td>\n",
       "      <td>0</td>\n",
       "      <td>Wingz12_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>10273</td>\n",
       "      <td>1601414361</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>14:19:21</td>\n",
       "      <td>Are we going to waste this generation at Chelsea?</td>\n",
       "      <td>(Commenting this here because the lads at r/ch...</td>\n",
       "      <td>Are we going to waste this generation at Chels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>epl</td>\n",
       "      <td>0</td>\n",
       "      <td>Messe_Lingard</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Question</td>\n",
       "      <td>10274</td>\n",
       "      <td>1601414505</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>14:21:45</td>\n",
       "      <td>Is $25 a good price for a New Jersey from an I...</td>\n",
       "      <td>Would you pay $25 from an Insta seller? I’ve b...</td>\n",
       "      <td>Is $25 a good price for a New Jersey from an I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>epl</td>\n",
       "      <td>0</td>\n",
       "      <td>TeddyMMR</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>:xpl: Premier League</td>\n",
       "      <td>10276</td>\n",
       "      <td>1601417535</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>15:12:15</td>\n",
       "      <td>People are giving Liverpool the league already</td>\n",
       "      <td>but am I missing something? \\n\\n* An unconvinc...</td>\n",
       "      <td>People are giving Liverpool the league already...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  target               author  score  comments  \\\n",
       "1974       epl       0  Year-Representative      1        11   \n",
       "1975       epl       0         maseone2nine      1         2   \n",
       "1976       epl       0             roots235      1        14   \n",
       "1977       epl       0             Wingz12_      1         0   \n",
       "1978       epl       0        Messe_Lingard      1         5   \n",
       "1979       epl       0             TeddyMMR      1         7   \n",
       "\n",
       "                       tag  index  created_utc        date      time  \\\n",
       "1974              Question  10267   1601401634  2020-09-29  10:47:14   \n",
       "1975            Discussion  10270   1601405960  2020-09-29  11:59:20   \n",
       "1976            Discussion  10272   1601413758  2020-09-29  14:09:18   \n",
       "1977                  none  10273   1601414361  2020-09-29  14:19:21   \n",
       "1978              Question  10274   1601414505  2020-09-29  14:21:45   \n",
       "1979  :xpl: Premier League  10276   1601417535  2020-09-29  15:12:15   \n",
       "\n",
       "                                                  title  \\\n",
       "1974        Someone please explain me the Handball rule   \n",
       "1975                     Spurs crowd noise is ATROCIOUS   \n",
       "1976  Better epl duo? Ronaldo and rooney vs mo and s...   \n",
       "1977  Are we going to waste this generation at Chelsea?   \n",
       "1978  Is $25 a good price for a New Jersey from an I...   \n",
       "1979     People are giving Liverpool the league already   \n",
       "\n",
       "                                                   post  \\\n",
       "1974  What constitutes a handball? What is considere...   \n",
       "1975  Every Spurs home game they absolutely BLAST th...   \n",
       "1976  For me, rooney and ronaldo had better link up ...   \n",
       "1977  (Commenting this here because the lads at r/ch...   \n",
       "1978  Would you pay $25 from an Insta seller? I’ve b...   \n",
       "1979  but am I missing something? \\n\\n* An unconvinc...   \n",
       "\n",
       "                                                alltext  \n",
       "1974  Someone please explain me the Handball rule Wh...  \n",
       "1975  Spurs crowd noise is ATROCIOUS Every Spurs hom...  \n",
       "1976  Better epl duo? Ronaldo and rooney vs mo and s...  \n",
       "1977  Are we going to waste this generation at Chels...  \n",
       "1978  Is $25 a good price for a New Jersey from an I...  \n",
       "1979  People are giving Liverpool the league already...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.reset_option('display.max_colwidth')\n",
    "df[1974:1980]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once columns were cleaned up and the `'alltext'` column was made (from `'title'` and `'selftext'`), I did one more pass over the new column to remove specific strings of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subreddit name strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the subreddits included in titles and body text are likely to be obvious tells for classification, which will be great for our model - helping to ensure high accuracy classification of posts for OverArmor. \n",
    "\n",
    "For EDA, however, removing them might be better, as it will give us a cleaner look at the common vernacular of each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.161347Z",
     "start_time": "2021-05-03T10:07:47.099813Z"
    }
   },
   "outputs": [],
   "source": [
    "titlecount_alltext_nfl = df[df['alltext'].str.contains('r/nfl')].shape[0] + df[df['alltext'].str.contains('r/NFL')].shape[0]\n",
    "titlecount_alltext_epl = df[df['alltext'].str.contains('r/premierleague')].shape[0] + df[df['alltext'].str.contains('r/PremierLeague')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.167597Z",
     "start_time": "2021-05-03T10:07:47.163578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'r/nfl' in 'alltext' column: 211\n",
      "Count of 'r/PremierLeague' in 'alltext' column: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Count of 'r/nfl' in 'alltext' column: {titlecount_alltext_nfl}\")\n",
    "print(f\"Count of 'r/PremierLeague' in 'alltext' column: {titlecount_alltext_epl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.171545Z",
     "start_time": "2021-05-03T10:07:47.169267Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can remove these for EDA later\n",
    "# nfl_titles, epl_titles, blanks = ('r/nfl', 'r/NFL'), ('r/premierleague', 'r/PremierLeague'), ('','')\n",
    "# df.replace(nfl_titles, blanks, inplace=True)\n",
    "# df.replace(epl_titles, blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.175628Z",
     "start_time": "2021-05-03T10:07:47.173288Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# df.replace(nfl_titles, blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.182579Z",
     "start_time": "2021-05-03T10:07:47.177312Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.replace(epl_titles, blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:47.189362Z",
     "start_time": "2021-05-03T10:07:47.185117Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['alltext'][100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, I replaced the code for various symbols with spaces. This will help me get at clean tokens when I get to the point of tokenizing and vectorizing for analysis.  \n",
    "\n",
    "My first attempts to replace the shortcodes below were unsuccessful (including a loop that would have made the process more efficient), so I searched for and found a good solution using some basic RegEx and kept it repetitive and simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T00:53:18.179475Z",
     "start_time": "2021-04-30T00:53:18.177228Z"
    }
   },
   "source": [
    "https://stackoverflow.com/questions/44227748/removing-newlines-from-messy-strings-in-pandas-dataframe-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:51.584708Z",
     "start_time": "2021-05-03T10:07:47.193812Z"
    }
   },
   "outputs": [],
   "source": [
    "# \\r (return)\n",
    "df.replace('\\r',' ', regex=True, inplace=True) \n",
    "\n",
    "# \\n (line break)\n",
    "df.replace('\\n',' ', regex=True, inplace=True)   \n",
    "\n",
    "# \\t (tab)\n",
    "df.replace('\\t',' ', regex=True, inplace=True)   \n",
    "\n",
    "# &amp; (&)\n",
    "df.replace('&amp;',' ', regex=True, inplace=True)   \n",
    "\n",
    "# &nbsp; (space)\n",
    "df.replace('&nbsp;',' ', regex=True, inplace=True)  \n",
    "\n",
    "# nbsp; (space, chained to other code)\n",
    "df.replace('nbsp;',' ', regex=True, inplace=True)    \n",
    "\n",
    "# # &gt; and &lt; (> and <)\n",
    "df.replace('&lt;','', regex=True, inplace=True)   \n",
    "df.replace('&gt;','', regex=True, inplace=True) \n",
    "\n",
    "# #x200b    # not working even after trying many variations of the code. see note below\n",
    "df.replace('x200B','', inplace=True) \n",
    "\n",
    "# '  (apostrophe)\n",
    "df.replace(\"'*\", '', regex=True, inplace=True)\n",
    "\n",
    "# **\n",
    "df.replace('[\\*\\*]', '', regex=True, inplace=True) \n",
    "\n",
    "# ‚Äì \n",
    "df.replace('‚Äì', '', inplace=True)\n",
    "\n",
    "# [  (left bracket)\n",
    "df.replace('\\[', '', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string 'x200b' represents a zero width space, but doesn't seem to become that literal string until it is actually displayed. My searches suggest that the issue might have something to do with changes in text encoding throughout the collection, ingestion, and cleaning process. More research warranted here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:51.606087Z",
     "start_time": "2021-05-03T10:07:51.589157Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12416 entries, 0 to 12415\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subreddit    12416 non-null  object\n",
      " 1   target       12416 non-null  int64 \n",
      " 2   author       12416 non-null  object\n",
      " 3   score        12416 non-null  int64 \n",
      " 4   comments     12416 non-null  int64 \n",
      " 5   tag          12416 non-null  object\n",
      " 6   index        12416 non-null  int64 \n",
      " 7   created_utc  12416 non-null  int64 \n",
      " 8   date         12416 non-null  object\n",
      " 9   time         12416 non-null  object\n",
      " 10  title        12416 non-null  object\n",
      " 11  post         12416 non-null  object\n",
      " 12  alltext      12416 non-null  object\n",
      "dtypes: int64(5), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Export for EDA and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T10:07:52.041375Z",
     "start_time": "2021-05-03T10:07:51.610047Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/2_clean/reddit_posts_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having collected and cleaned our data, I completed my delieverable for OverArmor's first request. \n",
    "\n",
    "It remains to be seen how my models will do, but based on the way the data looks, I expect decent results. I think there are strong enough differences between the language used in these subreddits that the model will be able to do a good job. \n",
    "\n",
    "Team names, city names, unique words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "656px",
    "left": "22px",
    "top": "110px",
    "width": "346px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
